{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training parameterized quantum circuits\n",
    "\n",
    "## Vocab\n",
    "+ Minimize <phi(theta)|H|phi(theta)> (this is the loss function)\n",
    "+ Quantum Fisher Information (Natural Gradients)\n",
    "+ Simultaneous Perturbation Stochastic Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "ansatz = RealAmplitudes(num_qubits=2, reps=1,\n",
    "                        entanglement='linear')\n",
    "# RealAmplitudes -> TwoLocal -> NLocal -> BlueprintCircuit -> QuantumCircuit\n",
    "print(ansatz.draw())\n",
    "ansatz = ansatz.decompose()\n",
    "ansatz.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate finite difference gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import Aer\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import PauliExpectation, CircuitSampler, StateFn, Z, I\n",
    "\n",
    "hamiltonian = Z ^ Z\n",
    "expectation = StateFn(hamiltonian, is_measurement=True) @ StateFn(ansatz)\n",
    "pauli_basis = PauliExpectation().convert(expectation)\n",
    "\n",
    "quantum_instance = QuantumInstance(Aer.get_backend('qasm_simulator'),\n",
    "                                   # we'll set a seed for reproducibility\n",
    "                                   shots = 8192, seed_simulator = 2718,\n",
    "                                   seed_transpiler = 2718)\n",
    "sampler = CircuitSampler(quantum_instance)\n",
    "\n",
    "def evaluate_expectation(theta):\n",
    "    value_dict = dict(zip(ansatz.parameters, theta))\n",
    "    result = sampler.convert(pauli_basis, params=value_dict).eval()\n",
    "    print(result)\n",
    "    return np.real(result)\n",
    "\n",
    "print(ansatz.num_parameters)\n",
    "point = np.random.random(ansatz.num_parameters)\n",
    "INDEX = 2\n",
    "\n",
    "EPS = 0.2\n",
    "# make identity vector with a 1 at index ``INDEX``, otherwise 0\n",
    "e_i = np.identity(point.size)[:, INDEX]\n",
    "print(e_i)\n",
    "\n",
    "plus = point + EPS * e_i\n",
    "minus = point - EPS * e_i\n",
    "\n",
    "print(plus)\n",
    "print(minus)\n",
    "\n",
    "finite_difference = (\n",
    "    evaluate_expectation(plus) - evaluate_expectation(minus)) / (2 * EPS)\n",
    "print(finite_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate with Qiskit gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.opflow import Gradient\n",
    "\n",
    "shifter = Gradient('fin_diff', analytic=False, epsilon=EPS)\n",
    "\n",
    "grad = shifter.convert(expectation, params=ansatz.parameters[INDEX])\n",
    "print(\"ansatz params : %s\" % (ansatz.parameters))\n",
    "print(\"ansatz params element : %s\" % (ansatz.parameters[INDEX]))\n",
    "print(\"grad : %s\" %(grad)) # grad object contain the info of which param to optimize already\n",
    "\n",
    "value_dict = dict(zip(ansatz.parameters, point))\n",
    "print(\"value dict : %s\" % (value_dict))\n",
    "\n",
    "sampler.convert(grad, value_dict).eval().real\n",
    "\n",
    "ansatz.bind_parameters([0,0,0,0])\n",
    "ansatz.draw('mpl') # in order to be displayed correctly it need to be at the end of the line, this is possible thanks to matplotlib_inline\n",
    "# this doesn't bind the value to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_point = np.random.random(ansatz.num_parameters)\n",
    "# Initialize \n",
    "initial_point = np.array([0.43253681, 0.09507794, 0.42805949, 0.34210341])\n",
    "\n",
    "gradient = Gradient().convert(expectation)\n",
    "gradient_in_pauli_basis = PauliExpectation().convert(gradient)\n",
    "sampler = CircuitSampler(quantum_instance)\n",
    "\n",
    "def evaluate_gradient(theta):\n",
    "    value_dict = dict(zip(ansatz.parameters, theta))\n",
    "    result = sampler.convert(gradient_in_pauli_basis,\n",
    "                             params=value_dict).eval()\n",
    "    return np.real(result)\n",
    "\n",
    "class OptimizerLog:\n",
    "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "    def update(self, _nfevs, _theta, ftheta, *_):\n",
    "        \"\"\"Save intermediate results. Optimizers pass many values\n",
    "        but we only store the third .\"\"\"\n",
    "        self.loss.append(ftheta)\n",
    "\n",
    "from qiskit.algorithms.optimizers import GradientDescent\n",
    "gd_log = OptimizerLog()\n",
    "gd = GradientDescent(maxiter=300,\n",
    "                     learning_rate=0.01,\n",
    "                     callback=gd_log.update)\n",
    "\n",
    "result = gd.minimize(\n",
    "    fun=evaluate_expectation,  # function to minimize\n",
    "    x0=initial_point,          # initial point\n",
    "    jac=evaluate_gradient      # function to evaluate gradient\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(gd_log.loss, label='vanilla gradient descent')\n",
    "plt.axhline(-1, ls='--', c='C3', label='target')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.opflow import NaturalGradient\n",
    "natural_gradient = (NaturalGradient(regularization='ridge')\n",
    "                    .convert(expectation))\n",
    "\n",
    "sampler = CircuitSampler(quantum_instance, caching=\"all\")\n",
    "\n",
    "def evaluate_natural_gradient(theta):\n",
    "    value_dict = dict(zip(ansatz.parameters, theta))\n",
    "    result = sampler.convert(natural_gradient, params=value_dict).eval()\n",
    "    return np.real(result)\n",
    "\n",
    "print('Vanilla gradient:', evaluate_gradient(initial_point))\n",
    "print('Natural gradient:', evaluate_natural_gradient(initial_point))\n",
    "\n",
    "qng_log = OptimizerLog()\n",
    "qng = GradientDescent(maxiter=300,\n",
    "                      learning_rate=0.01,\n",
    "                      callback=qng_log.update)\n",
    "\n",
    "result = qng.minimize(evaluate_expectation,\n",
    "                      initial_point,\n",
    "                      evaluate_natural_gradient)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(gd_log.loss, 'C0', label='vanilla gradient descent')\n",
    "plt.plot(qng_log.loss, 'C1', label='quantum natural gradient')\n",
    "plt.axhline(-1, c='C3', ls='--', label='target')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_algorithms.optimizers import SPSA\n",
    "spsa_log = OptimizerLog()\n",
    "spsa = SPSA(maxiter=300, learning_rate=0.01,\n",
    "            perturbation=0.01, callback=spsa_log.update)\n",
    "\n",
    "result = spsa.minimize(evaluate_expectation, initial_point)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(gd_log.loss, 'C0', label='vanilla gradient descent')\n",
    "plt.plot(qng_log.loss, 'C1', label='quantum natural gradient')\n",
    "plt.plot(spsa_log.loss, 'C0', ls='--', label='SPSA')\n",
    "plt.axhline(-1, c='C3', ls='--', label='target')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QN-SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_algorithms.optimizers import QNSPSA\n",
    "qnspsa_log = OptimizerLog()\n",
    "fidelity = QNSPSA.get_fidelity(ansatz,\n",
    "                               quantum_instance,\n",
    "                               expectation=PauliExpectation())\n",
    "qnspsa = QNSPSA(fidelity, maxiter=300, learning_rate=0.01,\n",
    "                                       perturbation=0.01,\n",
    "                                       callback=qnspsa_log.update)\n",
    "\n",
    "result = qnspsa.minimize(evaluate_expectation, initial_point)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(gd_log.loss, 'C0', label='vanilla gradient descent')\n",
    "plt.plot(qng_log.loss, 'C1', label='quantum natural gradient')\n",
    "plt.plot(spsa_log.loss, 'C0', ls='--', label='SPSA')\n",
    "plt.plot(qnspsa_log.loss, 'C1', ls='--', label='QN-SPSA')\n",
    "plt.axhline(-1, c='C3', ls='--', label='target')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QN-SPSA with decreasing learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autospsa_log = OptimizerLog()\n",
    "autospsa = SPSA(maxiter=300,\n",
    "                learning_rate=None,\n",
    "                perturbation=None,\n",
    "                callback=autospsa_log.update)\n",
    "\n",
    "result = autospsa.minimize(evaluate_expectation, initial_point)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(gd_log.loss, 'C0', label='vanilla gradient descent')\n",
    "plt.plot(qng_log.loss, 'C1', label='quantum natural gradient')\n",
    "plt.plot(spsa_log.loss, 'C0', ls='--', label='SPSA')\n",
    "plt.plot(qnspsa_log.loss, 'C1', ls='--', label='QN-SPSA')\n",
    "plt.plot(autospsa_log.loss, 'C3', label='Power-law SPSA')\n",
    "plt.axhline(-1, c='C3', ls='--', label='target')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "barren plateau problem : vanishing gradient when circuit depth and width increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.opflow import I # I is the identity matrix\n",
    "\n",
    "def sample_gradients(num_qubits, reps, local=False):\n",
    "    \"\"\"Sample the gradient of our model for ``num_qubits`` qubits and\n",
    "    ``reps`` repetitions.\n",
    "\n",
    "    We sample 100 times for random parameters and compute the gradient\n",
    "    of the first RY rotation gate.\n",
    "    \"\"\"\n",
    "    index = num_qubits - 1\n",
    "\n",
    "    # local or global operator\n",
    "    if local:\n",
    "        operator = Z ^ Z ^ (I ^ (num_qubits - 2))\n",
    "    else:\n",
    "        operator = Z ^ num_qubits\n",
    "\n",
    "    # real amplitudes ansatz\n",
    "    ansatz = RealAmplitudes(num_qubits, entanglement='linear', reps=reps)\n",
    "\n",
    "    # construct Gradient we want to evaluate for different values\n",
    "    expectation = StateFn(operator,\n",
    "                          is_measurement=True).compose(StateFn(ansatz))\n",
    "    grad = Gradient().convert(expectation,\n",
    "                              params=ansatz.parameters[index])\n",
    "\n",
    "    # evaluate for 100 different, random parameter values\n",
    "    num_points = 100\n",
    "    grads = []\n",
    "    for _ in range(num_points):\n",
    "        # points are uniformly chosen from [0, pi]\n",
    "        point = np.random.uniform(0, np.pi, ansatz.num_parameters)\n",
    "        value_dict = dict(zip(ansatz.parameters, point))\n",
    "        grads.append(sampler.convert(grad, value_dict).eval())\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global + linear depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = list(range(2, 13))\n",
    "reps = num_qubits  # number of layers = numbers of qubits\n",
    "gradients = [sample_gradients(n, r) for n, r in zip(num_qubits, reps)]\n",
    "\n",
    "fit = np.polyfit(num_qubits, np.log(np.var(gradients, axis=1)), deg=1)\n",
    "# np.polyfit returns a list of coefficent (in this case 2 because deg = 1)\n",
    "x = np.linspace(num_qubits[0], num_qubits[-1], 200)\n",
    "# 200 points equally spaced between num_qubits[0], num_qubits[-1]\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.semilogy(num_qubits,\n",
    "             np.var(gradients, axis=1),\n",
    "             'o-',\n",
    "             label='measured variance')\n",
    "plt.semilogy(x,\n",
    "             np.exp(fit[0] * x + fit[1]),\n",
    "             '--', c='C3',\n",
    "             label=f'exponential fit w/ {fit[0]:.2f}')\n",
    "plt.xlabel('number of qubits')\n",
    "plt.ylabel(r'$\\mathrm{Var}[\\partial_{\\theta 1}\\langle E(\\theta)\\rangle]$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global + constant depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = list(range(2, 13))\n",
    "fixed_depth_global_gradients = [sample_gradients(n, 1) for n in num_qubits]\n",
    "\n",
    "fit = np.polyfit(num_qubits, np.log(np.var(fixed_depth_global_gradients,\n",
    "                                           axis=1)), deg=1)\n",
    "x = np.linspace(num_qubits[0], num_qubits[-1], 200)\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.semilogy(num_qubits,\n",
    "             np.var(gradients, axis=1),\n",
    "             'o-',\n",
    "             label='global cost, linear depth')\n",
    "plt.semilogy(num_qubits, np.var(fixed_depth_global_gradients, axis=1),\n",
    "             'o-',\n",
    "             label='global cost, constant depth')\n",
    "plt.semilogy(x,\n",
    "             np.exp(fit[0] * x + fit[1]),\n",
    "             '--', c='C3',\n",
    "             label=f'exponential fit w/ {fit[0]:.2f}')\n",
    "plt.xlabel('number of qubits')\n",
    "plt.ylabel(r'$\\mathrm{Var}[\\partial_{\\theta 1}\\langle E(\\theta)\\rangle]$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local + linear depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = list(range(2, 13))\n",
    "linear_depth_local_gradients = [sample_gradients(n, n,\n",
    "                                        local=True) for n in num_qubits]\n",
    "fit = np.polyfit(num_qubits,\n",
    "                 np.log(np.var(linear_depth_local_gradients,axis=1)),\n",
    "                 deg=1)\n",
    "x = np.linspace(num_qubits[0], num_qubits[-1], 200)\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.semilogy(num_qubits, np.var(gradients, axis=1),\n",
    "             'o-', label='global cost, linear depth')\n",
    "plt.semilogy(num_qubits, np.var(fixed_depth_global_gradients, axis=1),\n",
    "             'o-', label='global cost, constant depth')\n",
    "plt.semilogy(num_qubits, np.var(linear_depth_local_gradients, axis=1),\n",
    "             'o-', label='local cost, linear depth')\n",
    "plt.semilogy(x, np.exp(fit[0] * x + fit[1]), '--', c='C3',\n",
    "             label=f'exponential fit w/ {fit[0]:.2f}')\n",
    "plt.xlabel('number of qubits')\n",
    "plt.ylabel(r'$\\mathrm{Var}[\\partial_{\\theta 1}\\langle E(\\theta)\\rangle]$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local + constant depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUBITS = 6\n",
    "OPERATOR = Z ^ Z ^ (I ^ (NUM_QUBITS - 4))\n",
    "\n",
    "def minimize(circuit, optimizer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        circuit (QuantumCircuit): (Partially bound) ansatz circuit to train\n",
    "        optimizer (Optimizer): Algorithm to use to minimize exp. value\n",
    "    Returns:\n",
    "        OptimizerResult: Result of minimization\n",
    "    \"\"\"\n",
    "    initial_point = np.random.random(circuit.num_parameters)\n",
    "\n",
    "    exp = StateFn(OPERATOR, is_measurement=True) @ StateFn(circuit)\n",
    "    grad = Gradient().convert(exp)\n",
    "\n",
    "    exp = PauliExpectation().convert(exp)\n",
    "    grad = PauliExpectation().convert(grad)\n",
    "\n",
    "    sampler = CircuitSampler(quantum_instance, caching=\"all\")\n",
    "\n",
    "    def loss(theta):\n",
    "        values_dict = dict(zip(circuit.parameters, theta))\n",
    "        return np.real(sampler.convert(exp, values_dict).eval())\n",
    "\n",
    "    def gradient(theta):\n",
    "        values_dict = dict(zip(circuit.parameters, theta))\n",
    "        return np.real(sampler.convert(grad, values_dict).eval())\n",
    "\n",
    "    return optimizer.minimize(loss, initial_point, gradient)\n",
    "\n",
    "def layerwise_training(ansatz, max_num_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ansatz (QuantumCircuit): Single circuit layer to train & repeat\n",
    "        max_num_layers (int): Maximum number of layers\n",
    "        optimizer (Optimizer): Algorithm to use to minimize exp. value\n",
    "    Returns:\n",
    "        float: Lowest value acheived\n",
    "        list[float]: Best parameters found\n",
    "    \"\"\"\n",
    "    optimal_parameters = []\n",
    "    for reps in range(max_num_layers):\n",
    "        ansatz.reps = reps\n",
    "\n",
    "        # fix the already optimized parameters\n",
    "        values_dict = dict(zip(ansatz.parameters, optimal_parameters))\n",
    "        partially_bound = ansatz.bind_parameters(values_dict)\n",
    "\n",
    "        result = minimize(partially_bound, optimizer)\n",
    "        optimal_parameters += list(result.x)\n",
    "        print('Layer:', reps, ' Best Value:', result.fun)\n",
    "\n",
    "    return result.fun, optimal_parameters\n",
    "\n",
    "ansatz = RealAmplitudes(4, entanglement='linear')\n",
    "optimizer = GradientDescent(maxiter=50)\n",
    "\n",
    "np.random.seed(12)  # for reproducibility\n",
    "fopt, optimal_parameters = layerwise_training(ansatz, 4, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum_info & primitives & algo\n",
    "\n",
    "Doc on how to use Estimator class: https://qiskit.org/ecosystem/ibm-runtime/stubs/qiskit_ibm_runtime.Estimator.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.quantum_info import Clifford\n",
    "\n",
    "X = SparsePauliOp(\"X\")\n",
    "\n",
    "qc = QuantumCircuit(1)\n",
    "qc.h(0)\n",
    "H = Clifford(qc).to_operator()\n",
    "\n",
    "plus = QuantumCircuit(1)\n",
    "plus.h(0)\n",
    "\n",
    "estimator = Estimator()\n",
    "values_plus = estimator.run([plus, plus], [X, H]).result().values\n",
    "\n",
    "print(values_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient finite difference (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit.quantum_info import Pauli\n",
    "from qiskit_aer.primitives import Estimator\n",
    "\n",
    "hamiltonian = Pauli('ZZ')\n",
    "\n",
    "estimator = Estimator(run_options={\"shots\":8192, \"seed_simulator\":2718})\n",
    "def evaluate_expectation(theta):\n",
    "    result = estimator.run(ansatz, hamiltonian, theta).result().values\n",
    "    # or we can set seed and shot like this \n",
    "    # result = estimator.run(ansatz, hamiltonian, theta, run_options={\"shots\":8192, \"seed_simulator\":2718}).result().values\n",
    "    print(result)\n",
    "    return np.real(result)\n",
    "\n",
    "point = np.random.random(ansatz.num_parameters)\n",
    "INDEX = 2\n",
    "\n",
    "EPS = 0.2\n",
    "# make identity vector with a 1 at index ``INDEX``, otherwise 0\n",
    "e_i = np.identity(point.size)[:, INDEX]\n",
    "print(e_i)\n",
    "\n",
    "plus = point + EPS * e_i\n",
    "minus = point - EPS * e_i\n",
    "\n",
    "print(plus)\n",
    "print(minus)\n",
    "\n",
    "finite_difference = (\n",
    "    evaluate_expectation(plus) - evaluate_expectation(minus)) / (2 * EPS)\n",
    "print(finite_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qiskit gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_algorithms.gradients import ParamShiftEstimatorGradient\n",
    "\n",
    "grad = ParamShiftEstimatorGradient(estimator)\n",
    "\n",
    "print(ansatz.parameters)\n",
    "print(hamiltonian)\n",
    "print(point)\n",
    "\n",
    "result = grad.run(ansatz, hamiltonian,[point], [ansatz.parameters[INDEX:INDEX+1]]).result()\n",
    "# Argument parameter of function run:\n",
    "# parameters: The sequence of parameters to calculate only the gradients of the specified parameters.\n",
    "\n",
    "gradients = result.gradients\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Gradient\n",
    "doc for migration : https://qiskit.org/documentation/migration_guides/opflow_migration.html#gradients\n",
    "\n",
    "Effect of Natural gradient can be achieved with QFI module\n",
    "\n",
    "**QFI :** Quantum Fisher information (Regularizer) [doc](https://qiskit.org/documentation/stubs/qiskit.algorithms.gradients.QFI.html#qiskit.algorithms.gradients.QFI)\n",
    "\n",
    "**QGT :** Quantum Geometric Tensor (QGT) [doc](https://qiskit.org/documentation/stubs/qiskit.algorithms.gradients.LinCombQGT.html)\n",
    "\n",
    "### Intuition of QFI\n",
    "\n",
    "+ Mathematically, the QFI is related to the second derivative of the quantum state's fidelity with respect to the parameter Î˜. The fidelity measures the similarity between two quantum states and is a way to quantify how distinguishable they are.\n",
    "\n",
    "+  QFI is a tool that helps you figure out how accurately you can make measurement. It's a number that tells you how much useful information you can get from your quantum system about what you're trying to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_algorithms.gradients import LinCombQGT, QFI\n",
    "import numpy as np\n",
    "\n",
    "qgt = LinCombQGT(estimator)\n",
    "qfi = QFI(qgt)\n",
    "\n",
    "result = qfi.run(qc,[point])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
